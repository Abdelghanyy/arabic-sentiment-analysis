{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pylab\n",
    "from matplotlib import pyplot\n",
    "import matplotlib as mpl\n",
    "from pylab import *\n",
    "from numpy import *\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reading_datast():\n",
    "    tweets=[]\n",
    "    training_labels=[]\n",
    "    training_dataset=[]\n",
    "    testing_labels=[]\n",
    "    testing_dataset=[]\n",
    "    training=[]\n",
    "    testing=[]\n",
    "    \n",
    "    for x in range(1,1001):\n",
    "        filename=\"twitter/positive/positive\"+str(x)+\".txt\"\n",
    "        file = open(filename, 'r')\n",
    "        lines = file.readlines()\n",
    "        tweet=str(lines)\n",
    "        new_tweet=tweet.replace(\"\\\\xa0\",\"\")\n",
    "        if(x in range(800)):\n",
    "            training_dataset.append(new_tweet[2:len(new_tweet)-4])\n",
    "            training.append((new_tweet[2:len(new_tweet)-4],\"pos\"))\n",
    "            training_labels.append(\"POS\")\n",
    "        else:\n",
    "            testing_dataset.append(new_tweet[2:len(new_tweet)-4])\n",
    "            testing.append((new_tweet[2:len(new_tweet)-4],\"pos\"))\n",
    "            testing_labels.append(\"POS\")\n",
    "            \n",
    "    for j in range(1,1001):\n",
    "        if(j not in [103,116,176,178,180,184,186,189,191]):\n",
    "            filename=\"twitter/negative/negative\"+str(j)+\".txt\"\n",
    "            file = open(filename, 'r')\n",
    "            lines = file.readlines()\n",
    "            tweet=str(lines)\n",
    "            new_tweet=tweet.replace(\"\\\\xa0\",\"\")\n",
    "        if(j in range(800)):\n",
    "            training_dataset.append(new_tweet[2:len(new_tweet)-4])\n",
    "            training.append((new_tweet[2:len(new_tweet)-4],\"neg\"))\n",
    "            training_labels.append(\"NEG\")\n",
    "        else:\n",
    "            testing_dataset.append(new_tweet[2:len(new_tweet)-4])\n",
    "            testing.append((new_tweet[2:len(new_tweet)-4],\"neg\"))\n",
    "            testing_labels.append(\"NEG\")\n",
    "    return tweets,training,testing,training_dataset,training_labels,testing_dataset,testing_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reading_new_dataset(filename):\n",
    "    labels = []\n",
    "    dataset=[]\n",
    "    \n",
    "    file = open(filename, 'r')\n",
    "    i=0\n",
    "    for line in file :\n",
    "        line=file.readline()\n",
    "        labels.append(line[-4:])\n",
    "        labels[i]=labels[i][0:3]\n",
    "        if (labels[i]==\"OBJ\"):\n",
    "            labels[i]=\"POS\"\n",
    "        dataset.append(line[0:len(line)-5])\n",
    "        i=i+1\n",
    "    return dataset,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
